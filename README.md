# KMeans Parallelization: Serial, OpenMP, and CUDA

This project implements **KMeans clustering** in three versions:  
ğŸŸ¢ Serial (C), ğŸŸ¡ OpenMP (multi-threaded CPU), ğŸ”µ CUDA (GPU).  
Designed for **high-performance computing coursework (CSCI 5451 @ UMN)** and extended for benchmarking and visualization.

---

## ğŸ§  Project Overview

This project performs **unsupervised learning on MNIST digit images**, clustering data points by pixel features into `k` clusters using the KMeans algorithm.

Each version was designed to progressively improve runtime:
- `kmeans_serial.c` â€“ Single-threaded C implementation
- `kmeans_omp.c` â€“ Multi-threaded version using OpenMP
- `kmeans_cuda.cu` â€“ GPU-accelerated version using CUDA

Each implementation:
- Reads MNIST-like feature data from a plain-text file
- Iteratively updates cluster centers and assignments
- Tracks convergence via assignment changes
- Outputs cluster center images (`.pgm`) and a confusion matrix

This project was originally based on [Assignment 3 of UMN CSCI 5451](https://www-users.cse.umn.edu/~kauffman/5451/a3.html), which specified the core algorithm and dataset format.

---

## ğŸ“ Repository Structure

```
kmeans-parallel/
â”œâ”€â”€ kmeans_serial.c           # Serial version
â”œâ”€â”€ kmeans_omp.c              # OpenMP version
â”œâ”€â”€ kmeans_cuda.cu            # CUDA version
â”œâ”€â”€ kmeans_util.c/cu/h        # Shared utility code
â”œâ”€â”€ Makefile                  # Easy compilation
â”œâ”€â”€ scripts/                  # Benchmarking scripts
â”‚   â”œâ”€â”€ kmeans-omp-time.sh
â”‚   â””â”€â”€ kmeans-cuda-time.sh
â”œâ”€â”€ results/                  # Sample output (txt/pgm)
â”œâ”€â”€ test/                     # Org-mode test runs
â”œâ”€â”€ mnist-data/               # Data files or download instructions
â”œâ”€â”€ kmeans.py                 # Optional Python reference implementation
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Build

### âœ… Using the Makefile
```bash
make
```

### ğŸ”§ Or compile manually:

```bash
gcc -O3 kmeans_serial.c kmeans_util.c -o kmeans_serial -lm

gcc -O3 -fopenmp kmeans_omp.c kmeans_util.c -o kmeans_omp -lm

nvcc -O3 kmeans_cuda.cu kmeans_util.cu -o kmeans_cuda
```

---

## â–¶ï¸ Run

Each binary takes the following arguments:
```bash
./<binary> <datafile> <nclust> [savedir] [maxiter]
```

### Example:
```bash
./kmeans_serial mnist-data/digits_all_5e3.txt 20 results_serial 100
./kmeans_omp mnist-data/digits_all_5e3.txt 20 results_omp 100
./kmeans_cuda mnist-data/digits_all_5e3.txt 20 results_cuda 100
```

---

## ğŸ“Š Benchmarking

### CUDA:
```bash
bash scripts/kmeans-cuda-time.sh
```

### OpenMP:
```bash
bash scripts/kmeans-omp-time.sh
```

These scripts:
- Test on varying dataset sizes (5k, 10k, 30k MNIST samples)
- Iterate over OpenMP thread counts (1â€“32)
- Log timing output using `/usr/bin/time`

---

## ğŸ“· Output Samples

- `results/*.txt` â€“ runtime logs, confusion matrix, convergence
- `results/*.pgm` â€“ grayscale visualizations of cluster centers
- `labels.txt` â€“ original and predicted labels for inspection

---

## ğŸ“˜ Dataset Format (from A3 instructions)

Each line of the dataset:
```
[label] : <f1> <f2> ... <f784>
```
- `label` is a ground-truth digit [0â€“9]
- `:` is ignored
- `f1..f784` are flattened grayscale pixel intensities (28x28)

You may generate your own data using MNIST or use sample files like:
- `digits_all_5e3.txt`
- `digits_all_1e4.txt`

---

## ğŸ’¡ Key Learning Outcomes

- Implemented KMeans from scratch in C and CUDA
- Compared performance across CPU and GPU environments
- Used OpenMP's thread reduction and critical sections
- Optimized CUDA memory access patterns
- Benchmarked convergence rates and runtime across versions

---

## ğŸ“ Contact

Made with â¤ï¸ by [Your Name](https://your-portfolio.com)  
Inspired by [CSCI 5451: High Performance Computing](https://www-users.cse.umn.edu/~kauffman/5451/)
